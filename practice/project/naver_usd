import requests
from bs4 import BeautifulSoup
import pandas as pd

# https://finance.naver.com/marketindex/exchangeDetail.naver?marketindexCd=FX_USDKRW -> 네이버 페이 증권 달러 환율


# end_page만큼 크롤링. 1페이지당 10일치의 정보가 있음
end_page = 10
page = 0

data = []
for k in range(1, end_page+1) :
    page +=1
    url = f"https://finance.naver.com/marketindex/exchangeDailyQuote.naver?marketindexCd=FX_USDKRW&page={page}"
    res = requests.get(url)
        #받은 정보 html기반으로 파싱
    soup = BeautifulSoup(res.text, "html.parser")
        #tbody 기준으로 파싱
    tbody = soup.find("tbody")
        # tbody 내부의 모든 tr속성 찾기 
    trs = tbody.find_all("tr")
        # 모든 tr속성에 대해서 date, num 속성을 추출하고 이를 data(리스트)에 넣음
    for i in trs:
        date = i.find("td", attrs={"class": "date"})
        price = i.find("td", attrs={"class": "num"})
        data.append({"date": date.text, "usd_price": price.text})
    print(f"{page}번째 페이지 크롤링 완료")



df = pd.DataFrame(data)
df.to_excel("naver_usd_crawling.xlsx", index="False", engine="openpyxl")
print("저장완료")

