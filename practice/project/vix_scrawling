import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import json

MAX = 50

#필요한 url로 변경하기 용인데 그냥 반복문에 통합시켜버려도됨
def url_convert(i) :
    return f'https://api.stock.naver.com/index/.VIX/price?page={i}&pageSize=10'



lists = []

# MAX만큼 반복
for i in range(1,MAX) :
  vix = requests.get(url_convert(i))
    # bs4로 슬라이싱
  vix2 = BeautifulSoup(vix.text, 'lxml')
    # 아이디가 p인 html을 기준으로 슬라이싱
  jsons = vix2.find('p').text
    # 슬라이싱 결과 나온 json파일을 로든
  data = json.loads(jsons)
  for item in data:
    # data 내부 모든 json파일들에 대해 아래 두 속성에 해당하는 값 가져오기
    print(item["localTradedAt"][:10], item["closePrice"])
    lists.append({"date":item["localTradedAt"][:10], "close_value":item["closePrice"]})




print("---"*20)
print(lists)

df = pd.DataFrame(lists)
df.to_excel("vix_data.xlsx", index=False, engine='openpyxl')
    

# tbody = vix2.find('localTradedAt')

# print(tbody)
# #print(vix2)
