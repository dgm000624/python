{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image1 = cv2.imread(\"faces/img01.jpg\")\n",
    "cv2.imshow(\"Face\", image1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "da15c045fe14201a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "face_images = []\n",
    "for i in range(1, 16):\n",
    "    file = f\"faces/img{i:02d}.jpg\"\n",
    "    image = cv2.imread(file)\n",
    "    image = cv2.resize(image, (64, 64)) # 64x64 RGB -> BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #BGR -> RGB\n",
    "    face_images.append(image)"
   ],
   "id": "c442c432492dbbaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def show_image(row, col, images):\n",
    "    (_, ax) = plt.subplots(row, col, figsize= (row, col))\n",
    "    for i in range(row):\n",
    "        for j in range(col) :\n",
    "            if row <= 1:\n",
    "                axis = ax[j]\n",
    "            else:\n",
    "                axis = ax[i,j]\n",
    "                axis.imshow(images[i*col+j])\n",
    "    plt.show()"
   ],
   "id": "73d62ef0f9c8a9f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "show_image(3, 5, face_images)",
   "id": "79f7e71dafbaea7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "animal_images = []\n",
    "for i in range(1, 16):\n",
    "    file = f\"animals/img{i:02d}.jpg\"\n",
    "    image = cv2.imread(file)\n",
    "    image = cv2.resize(image, (64, 64)) # 64x64 RGB -> BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #BGR -> RGB\n",
    "    animal_images.append(image)"
   ],
   "id": "a590a23841c09b93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(animal_images)",
   "id": "723fb3bc8c61ca8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def show_animals(row, col, images):\n",
    "    (_, ax) = plt.subplots(row, col, figsize= (row, col))\n",
    "    for i in range(row):\n",
    "        for j in range(col) :\n",
    "            if row <= 1:\n",
    "                axis = ax[j]\n",
    "            else:\n",
    "                axis = ax[i,j]\n",
    "                axis.imshow(images[i*col+j])\n",
    "    plt.show()"
   ],
   "id": "de1b5a88ac3710b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "show_animals(3,5,animal_images)",
   "id": "f5f6668f886ed335",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y = np.array([(1,0)] * len(face_images) + [(0,1)] * len(animal_images))",
   "id": "9d22a051311b5e35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(y)        # 레이블(원핫 인코딩)",
   "id": "dcc8a2409f288f50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = face_images + animal_images #이미지 합쳐서 하나로 만들기\n",
    "print(x)\n",
    "print(len(x))"
   ],
   "id": "2898af33daefc9d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train = np.array(x)   # 사용가능한 형태(넘파이)로 변경\n",
    "X_train = X_train / 255.0"
   ],
   "id": "9549ed09f952a962",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(X_train.shape)        # 제대로 생성이 되었나 확인",
   "id": "99b9d2ceb751a837",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = keras.Sequential(name=\"FACE_DETECTOR\")\n",
    "model.add(keras.layers.Input(shape = (64,64,3)))\n",
    "model.add(keras.layers.Conv2D(128,(3,3), activation = \"relu\"))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(keras.layers.Conv2D(64,(3,3), activation = \"relu\"))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(keras.layers.Conv2D(32,(3,3), activation = \"relu\"))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(keras.layers.Conv2D(32,(3,3), activation = \"relu\"))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "# DNN\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))"
   ],
   "id": "99b12ab2ae8c1faf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.summary()",
   "id": "29e2b293d3d5df1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.compile(optimizer=\"adam\", loss = \"categorical_crossentropy\",\n",
    "              metrics=[\"categorical_accuracy\"])"
   ],
   "id": "cb9eee8b08f90b49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "history = model.fit(X_train, y, epochs=200)\n",
    "model.save(\"FACE_DETECTOR.keras\")"
   ],
   "id": "3bc40aac6238e414",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"모델의 정확도 : {model.evaluate(X_train, y)}\" )",
   "id": "19d74de7f1483bc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_images = []\n",
    "test_images.clear()\n",
    "for i in range(1, 12):\n",
    "    temp_image = cv2.imread(f\"test_images/img{i:02d}.jpg\")\n",
    "    temp_image = cv2.resize(temp_image, (64,64))\n",
    "    temp_image = cv2.cvtColor(temp_image, cv2.COLOR_BGR2RGB)\n",
    "    test_images.append(temp_image)"
   ],
   "id": "302933b0f0eb4a2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_images = np.array(test_images)\n",
    "test_X = test_images / 255.0"
   ],
   "id": "1935a736593e13e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.predict(test_X)",
   "id": "ee9d01ef0742bf1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cnn_model = keras.models.load_model(\"FACE_DETECTOR.keras\") #학습 모델 불러오기",
   "id": "a9b4ecea7c47ddb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cnn_model.predict(test_X)",
   "id": "e37b658b4b040276",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(cnn_model.predict(test_X).round(0)) #[1. 0.]=인간, [0. 1.]=비인간",
   "id": "6f7e3825945ce98c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T05:42:57.200950Z",
     "start_time": "2025-10-27T05:42:57.195680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_images = []\n",
    "for i in range(1, 3):\n",
    "    file = f\"test_image/test{i}.jpg\"\n",
    "    images = cv2.imread(file)\n",
    "    images = cv2.resize(images, (64, 64)) # 64x64 RGB -> BGR\n",
    "    image = cv2.cvtColor(images, cv2.COLOR_BGR2RGB) #BGR -> RGB\n",
    "    output_images.append(image)"
   ],
   "id": "8aaaa89b39f29403",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T05:43:01.536605Z",
     "start_time": "2025-10-27T05:43:00.145813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv2.imshow(\"test\",cv2.imread(\"test_image/test1.jpg\"))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "83d1099cbab499d4",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T05:43:04.212383Z",
     "start_time": "2025-10-27T05:43:02.766453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv2.imshow(\"test\",cv2.imread(\"test_image/test2.jpg\"))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "ad05b1296cd7d840",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T05:43:06.189349Z",
     "start_time": "2025-10-27T05:43:06.187465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_images = np.array(output_images)\n",
    "self_data = output_images/255.0"
   ],
   "id": "8af04ad74b95d1f7",
   "outputs": [],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T05:43:16.570535Z",
     "start_time": "2025-10-27T05:43:16.522313Z"
    }
   },
   "cell_type": "code",
   "source": "model.predict(self_data).round(5)",
   "id": "a76877033ae3f974",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00916, 0.99084],\n",
       "       [1.     , 0.     ]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 171
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "126ce6625652e4aa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
