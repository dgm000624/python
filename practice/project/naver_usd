import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

# https://finance.naver.com/marketindex/exchangeDetail.naver?marketindexCd=FX_USDKRW -> 네이버 페이 증권 달러 환율

MAX_PAGES = 50
REQUEST_DELAY = 1.5


def crawl_exchange_rate(max_pages):
    print("달러 환율 데이터 크롤링 시작")

    BASE_URL = "https://finance.naver.com"
    SUB_PATH = "/marketindex/exchangeDailyQuote.naver?marketindexCd=FX_USDKRW"
    all_exchange_data = []

    for page_num in range(1, max_pages + 1):
        target_url = f"{BASE_URL}{SUB_PATH}&page={page_num}"
        print(f"{page_num} 페이지에 데이터 요청")

        try:
            response = requests.get(target_url)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, 'html.parser')

            table = soup.find('table', {'class': 'tbl_exchange today'})

            if table:
                rows = table.find('tbody').find_all('tr')

                if not rows:
                    print(f"데이터 행을 찾을 수 없습니다")
                    break

                for row in rows:
                    cols = row.find_all('td')
                    if len(cols) >= 2:
                        date = cols[0].text.strip()
                        price = cols[1].text.strip()

                        price = price.replace(',', '').strip()

                        all_exchange_data.append([date, price])

        except requests.exceptions.RequestException as e:
            print(f"오류 발생: {e}")
            break

        time.sleep(REQUEST_DELAY)

    return all_exchange_data


exchange_data = crawl_exchange_rate(MAX_PAGES)

if exchange_data:
    df_exchange = pd.DataFrame(exchange_data, columns=['날짜', '원/달러 환율 (매매기준율)'])
    df_exchange['원/달러 환율 (매매기준율)'] = pd.to_numeric(df_exchange['원/달러 환율 (매매기준율)'], errors='coerce')

    df_exchange.to_excel('usd_krw_exchange.xlsx', index=False, engine='openpyxl')
    print("저장되었습니다.")
